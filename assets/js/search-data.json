{
  
    
        "post0": {
            "title": "Web Scraping Property Listings Project Using Beautiful Soup",
            "content": "This Jupyter notebook has been made by Mladen Tsolov . I have written important information in the beginning of this project that is crucial before we get into a web scraping of a website. Please take your time to read it and do not ignore it, because a web scraping can lead to breaking the law. . . General information . In this Jupyter notebook we will be doing web scraping of a Bulgarian website for properties. . After we collect the data we will inspect it in more details. . But before we begin we have to make sure that the website allows web scraping. Some websites do not allow it and we can break the law if we collect data without permission. . It is not very hard to see if a website allows web scraping. All we have to do is to append &#39;/robots.txt&#39; to the main website url: . https://www.imot.bg/robots.txt . The result that we get is: . Sitemap: https://www.imot.bg/sitemap/index.xml . User-agent: * - for all users using the website . Disallow: - it is left empty, which means that nothing is restricted . . Information about the website. . The website that we will use in this example is only in Bulgarian language. It has many sections like: Buying, Selling, Renting, Looking for new built properties and many more. . In order to navigate within the website you can right click on it and select: &#39;Translate to English&#39; . Imot.bg lists properties predominantly in Bulgaria and Greece, whereas http://worldwide-search.imot.bg/ has listings all over the world. . In this example we will focus only on https://www.imot.bg/ (imot means property) . The main page shows us the Bulgarian municipalities borders . Clicking on one of them will trigger a search window like the one given here: . https ://ww w.im ot.bg/pcgi/imot.cgi?act=3&amp;slink= 7hou98 &amp;f1=1 . PLEASE NOTE: The reason why I have put spaces in the link above is, because in time it will not work, because the code for the municipality will be changed. . 7hou98 - is the code for the municipality (please note that the code changes with time) . =1 - that is the current page (=0 and =1 yeald same result) . Each municipality page has exactly 40 property results and 25 pages of results. . . Having said that there is a bit more preparation that we need to do. . We have to make sure that the webpage link is in the right format like the one below: . https ://ww w.im ot.bg/pcgi/imot.cgi?act=3&amp;slink= 7hou98 &amp;f1=1 . We can see that it ends with &#39;=1&#39;, that means if I wanted to see the second page I can change the 1 with 2 and it will open the second page. . In order to navigate in the webpage and find the relevant information that we would like to scrape we have &#39;inspect&#39; it by right clicking anywhere in the webpage and pressing &#39;view page source&#39; or &#39;inspect&#39;. In that way we can see the separate objects/tags and tables that combined together form the webpage that we see. Furthermore we can use &#39;Ctrl + F&#39;, which opens a search window with the help of which we can find information faster. . . How the information that we will scrape looks like? . The information is &quot;hidden&quot; in tags (from HTML). Tags are information containers used in websites. . In this cell we can see one table tag that has all the information that we need. The majority of that table tag is deleted for clarity. . table tag - depending on the property the style of this tag can vary. It can be ordinary listing, vip listing or top listing. This table tag represents a single property listing. Within it we can gather additional information. . table width=&quot;660&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; border=&quot;0&quot; style=&quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/top_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot; . td tag - we can get information about the location and the number of rooms of the property. It is a bit tricky to get to the information hidden in the &#39;alt&#39; parameter (Someone made mistake with the number of rooms for this listing, in the tags below it is said that it is one bedroom apartment). . td a class=&quot;photoLink&quot; img src=&quot;&quot; style=&quot;object-fit: cover;&quot; width=&quot;200&quot; height=&quot;150&quot; border=&quot;0&quot; alt=&quot;2-bedroom apartment for sale, Gorna Oryahovitsa, Veliko Tarnovo region&quot; . div tag - We can get the price of the property using the class of the div . div class=&quot;price&quot; img BGN 58,000 . a tag or link tag - Number of rooms, using the class . a href=&quot;&quot; class=&quot;lnk1&quot; One-bedroom apartment for sale in . a tag or link tag - Location, using the class . a href=&quot;&quot; class=&quot;lnk2&quot; Gorna Oryahovitsa, Veliko Tarnovo region . td tag - Additional information about the listing . td width=&quot;520&quot; colspan=&quot;3&quot; height=&quot;50&quot; style=&quot;padding-left:4px&quot; 69 sq.m, Prolet quarter, ONE BEDROOM APARTMENT EXCLUSIVELY! WE ARE WITH THE KEY! style=&quot;vertical-align: inherit;&quot;&gt; Property Tarnovgrad offers one-bedroom panel apartment ..., tel .: 089 . All the tags above are for one property listing. . . Language and translation . The Imot.bg website is in Bulgarian. There are ways to convert the information into English. . One is to use Module that will translate the information into this notebook - googletrans or googletrans new (I used google trans new). . Other is to scrape the website, save the dataframe as CSV file and then translate the file with Google Translate. . I will do both and compare them to see which one is better. . . Actual Web scraping . Plan of action. . We will first do web scraping to see how it works and later on we will translate the results. I will try to explain along the way where needed. . from bs4 import BeautifulSoup import requests import urllib.request # Libraries for Data Processing import pandas as pd import numpy as np import matplotlib.pyplot as plt # Library for translation into English from google_trans_new import google_translator # The two lines below allow us to see all the columns without truncation. # It allows us to see the dataset better. pd.options.display.max_columns = None pd.options.display.max_rows = None . As mentioned before it is interesting to see that &#39;=0&#39; gives the same result as &#39;=1&#39; (that was for the page number). We do not want repetitions, so we will start with &#39;=1&#39;. We can define a variable called &#39;url&#39; that will store string with the website&#39;s address. . We can define a function called &#39;connection&#39; that will make the connection between us and the website and will return number, which will tell us if it was sucessful. . def connection(page): &#39;&#39;&#39; This function is used to change the number of the page from the link. So after we finish with collecting the data from page 1, we can continue to page 2 of that webpage and so on. &#39;&#39;&#39; # https://router-network.com/tools/what-is-my-user-agent -&gt; to find the &#39;user agent&#39; # Or google -&gt; &#39;what is my user agent&#39; # &#39;user agent&#39; is a mediator between the user and the internet it holds technical information # About the device (the computer used) and the software # The &#39;user agent&#39; is unique for every person on the internet headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36&#39;} # F-string in which we can change the number of the page # Note that &#39;page&#39; in the f-string is the parameter of the function url = f&#39;https://www.imot.bg/pcgi/imot.cgi?act=3&amp;slink=7o949b&amp;f1={page}&#39; r = requests.get(url, headers) # Checks if there is a connection between the user and the webpage return r.status_code print(connection(1)) # https://developer.mozilla.org/en-US/docs/Web/HTTP/Status # Informational responses (100–199) # Successful responses (200–299) # Redirection messages (300–399) # Client error responses (400–499) # Server error responses (500–599) # If we get 200 in return then all is working fine. . 200 . In the cell above, where I wrote about the tags I mentioned about &#39;div&#39; tag that has stored the price of the property. We can use it to count the number of properties for a single page -&gt; div class=&quot;price&quot; img BGN 58,000 . def extract(page): &#39;&#39;&#39; This function is used to change the number of the page from the link. So after we finish with collecting the data from page 1, we can continue to page 2 of that webpage and so on. &#39;&#39;&#39; # https://router-network.com/tools/what-is-my-user-agent -&gt; to find the &#39;user agent&#39; # or google -&gt; &#39;what is my user agent&#39; # &#39;user agent&#39; is a mediator between the user and the internet it holds technical information # about the device (the computer used) and the software # the &#39;user agent&#39; is unique for every person on the internet headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36&#39;} # f-string in which we can change the number of the page # note that &#39;page&#39; in the f-string is the parameter of the function url = f&#39;https://www.imot.bg/pcgi/imot.cgi?act=3&amp;slink=7o949b&amp;f1={page}&#39; r = requests.get(url, headers) soup = BeautifulSoup(r.content, &#39;html.parser&#39;) return soup def transform(soup): &#39;&#39;&#39; This function is used to find and collect information. &#39;&#39;&#39; divs = soup.find_all(&#39;div&#39;, class_ = &#39;price&#39;) return len(divs) search = extract(1) print(transform(search)) # we get as a result 40 # that is the number of property listings per page . 40 . If the result is 0, that means that the code for the municipality is changed and that is the main reason. We should get 40 as a result. . . We can use the code for the extract function from the cell above. In that way we can focus on the new lines of code. . From the cell above we can see that we get 40 as a result, that is the number of the properties for one page. . In the cell below we will use the same functions &#39;extract&#39; and &#39;transform&#39; but this time we will collect the information for one property listing. . def transform_property(soup): &#39;&#39;&#39; This function is used to find and collect information. &#39;&#39;&#39; property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;) print(property_info.strip()) price_div = soup.find(&#39;div&#39;, class_ = &#39;price&#39;) print(price_div.text.strip()) rooms_a = soup.find(&#39;a&#39;, class_ = &#39;lnk1&#39;) print(rooms_a.text.strip()) location_a = soup.find(&#39;a&#39;, class_ = &#39;lnk2&#39;) print(location_a.text.strip()) info = soup.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;) print(info.text.strip()) return len(price_div) search = extract(1) print(transform_property(search)) . Обява продава къща, гр. Елена, област Велико Търново 50 000 EUR Продава КЪЩА гр. Елена, област Велико Търново 146 кв.м, двор 2200 кв.м, с.Дърлевци, Реновирана къща със съхранени елементи на автентичното строителство, характерно за района от края на ..., тел.: 0887902715 3 . Yey! We got something. . It would have been nice to go to https://translate.google.com/ . Paste the URL of the website we want translated, select to translate from Bulgarian into English and click the URL on the right hand site. We can see that the website is translated. We can copy that link and paste it as a new value for the &#39;url&#39; variable in &#39;extract&#39; function. . https ://www- imot-bg .translate. goog/pcgi/imot.cgi?act=3&amp;slink=7hzunk&amp;f1=1&amp;_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en-GB . just replace &#39;=1&#39; with &#39;={page}&#39; . Unfortunately, it does not work. . . Each property listing has a unique style for the table that contains the basic information about it - location, price and general information. Depending on the property there can be three styles: Regular, TOP and VIP listing. . We can use them to collect the information from all listings. . Starting from the cell below we will focus on the &#39;transform&#39; function and how to alter the code in order to make it more functional. . def transform(soup): &#39;&#39;&#39; This function is used to find and collect information. &#39;&#39;&#39; # Finds all &#39;div&#39; tags that store the price for each listing # It is used to locate all the listings on the page price_div = soup.find_all(&#39;div&#39;, class_ = &#39;price&#39;) # The different styles of the tables that we gather information are defined # One table = one property listing style_0 = &quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/top_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot; style_1 = &quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/vip_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot; style_2 = &quot;margin-bottom:0px; border-top:#990000 1px solid;&quot; # We can find all tables that have the styles from above table_0 = soup.find_all(&#39;table&#39;, style=style_0) table_1 = soup.find_all(&#39;table&#39;, style=style_1) table_2 = soup.find_all(&#39;table&#39;, style=style_2) # for loop to collect the listings for tables with style_0 for i in table_0: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_0 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_0) # for loop to collect the listings for tables with style_1 for i in table_1: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_1 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_1) # for loop to collect the listings for tables with style_2 for i in table_2: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_2 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_2) # This return will show how many listings are with style_0, _1 or _2. # Please note that the sum must be 40 return len(table_0), len(table_1), len(table_2), len(price_div) # we create empty list to which we append info property_list = [] search = extract(1) print(transform(search)) print(len(property_list)) print(property_list) . (21, 19, 0, 40) 40 [{&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;50 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;146 кв.м, двор 2200 кв.м, с.Дърлевци, Реновирана къща със съхранени елементи на автентичното строителство, характерно за района от края на ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;65 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;144 кв.м, двор 739 кв.м, с.Граматици, Атрактивен имот в балкана. Двуетажна, частично обзаведена тухлена сграда. Имот с целогодишен достъп ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;85 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Златарица, област Велико Търново&#39;, &#39;info&#39;: &#39;185 кв.м, двор 613 кв.м, Primo+ Велико Търново Ви предлага просторна и уютна , тухлена къща след тотален ремонт, с и добро ..., тел.: 0887177900&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;115 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Павликени, област Велико Търново&#39;, &#39;info&#39;: &#39;123 кв.м, двор 750 кв.м, Имоти Търновград Ви предлага двуетажна ОБЗАВЕДЕНА къща в гр. Павликени. Имотът се намира на тиха, ас ..., тел.: 0885168782&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;5 999 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Полски Тръмбеш, област Велико Търново&#39;, &#39;info&#39;: &#39;140 кв.м, двор 3000 кв.м, село Орловец, Тухлена къща с голям двор 3000 кв.м и стопански постройки в село Орловец на 30 км от Велико Търново ..., тел.: 0899855101&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;85 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Балван, област Велико Търново&#39;, &#39;info&#39;: &#39;160 кв.м, двор 1250 кв.м, ВИРТУАЛЕН ТУР! ЕКСКЛУЗИВНО! Реновирана двуетажна къща с допълнителни постройки в село Балван Атракти ..., тел.: 0899921394&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;155 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Бръчковци, област Велико Търново&#39;, &#39;info&#39;: &#39;206 кв.м, двор 826 кв.м, На Вашето внимание представяме един изключителен имот в красивият Еленски Балкан, а именно, новопост ..., тел.: 0884905169&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;252 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Бръчковци, област Велико Търново&#39;, &#39;info&#39;: &#39;220 кв.м, двор 900 кв.м, Агенция Имоти Консулт предлага имота разположен в живописния Еленски балкан, на брега на язовир ..., тел.: 0988871433&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;49 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Джулюница, област Велико Търново&#39;, &#39;info&#39;: &#39;87 кв.м, двор 680 кв.м, Aгенция за недвижими имоти SUNNY HOMES предлага за продажба реновирана къща с двор в с. Джулюница. ..., тел.: 0882373785&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;300 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Лагерите, област Велико Търново&#39;, &#39;info&#39;: &#39;1332 кв.м, двор 12400 кв.м, Тухла 1947 г., ЕКСКЛУЗИВНО: ВНУШИТЕЛНА РЕЗИДЕНЦИЯ С ИСТОРИЯ И СТРАТЕГИЧЕСКА ЛОКАЦИЯ - МЛАДЕЖКИ ЛАГЕР ХАИНБОАЗ , ..., тел.: 0889590019&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;165 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Леденик, област Велико Търново&#39;, &#39;info&#39;: &#34;260 кв.м, двор 488 кв.м, ID:12699 ЕКСКЛУЗИВНО !!! Прекрасен имот с панорамна гледка в предпочитано село!!! &#39;&#39;Ту Бългерия&#39;&#39;- н ..., тел.: 0876 39 54 29&#34;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;27 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Лесичери, област Велико Търново&#39;, &#39;info&#39;: &#39;120 кв.м, двор 550 кв.м, Агенция за недвижими имоти Акценти Пропъртис ООД Ви предлагаме хубав и добре поддържан имот, разпо ..., тел.: 0887 573 633&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;33 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Палици, област Велико Търново&#39;, &#39;info&#39;: &#34;120 кв.м, двор 1500 кв.м, ID:20517 &#39;&#39;Ту Бългерия&#39;&#39; недвижими имоти предлага тухлена двуетажна къща с магазин в с.Палици. Селот ..., тел.: 0878 48 47 40&#34;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;160 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Палици, област Велико Търново&#39;, &#39;info&#39;: &#39;300 кв.м, двор 1600 кв.м, SUNNY HOMES недвижими имоти предлага къща с двор, РЗП 300 кв.метра, дворно място 1600 кв.м., камъ ..., тел.: 0882373785&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;54 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Самоводене, област Велико Търново&#39;, &#39;info&#39;: &#34;80 кв.м, двор 500 кв.м, 2 ет., Агенция за недвижими имоти &#39;Оникс&#39; Ви предлага масивна двуетажна къща на калкан във високата част в ..., тел.: 0885 971 518&#34;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;80 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;с. Хотница, област Велико Търново&#39;, &#39;info&#39;: &#39;100 кв.м, двор 1490 кв.м, ЕКСКЛУЗИВНО! Имоти Търновград Ви предлага реновирана къща в село Русаля, намираща се в близост до ре ..., тел.: 0895476397&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;250 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ХОТЕЛ&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;6878 кв.м, Тухла 2005 г., АRCO REAL ESTATE, ПРЕДЛАГА КОМПЛЕКС С КЪЩИ ЗА ОТДИХ. Близко до комплекса е град Елена, който е извес ..., тел.: 0894550682&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;400 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ХОТЕЛ&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;1427 кв.м, Тухла 2007 г., ЕРА ИМОТИ РУСЕ Ви предлага уникалната възможност да инвестирате в собствен приказен хотел в живописн ..., тел.: 0886601920&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;300 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ХОТЕЛ&#39;, &#39;location&#39;: &#39;с. Лагерите, област Велико Търново&#39;, &#39;info&#39;: &#39;1332 кв.м, Тухла 1947 г., ЕКСКЛУЗИВНО: Емблематичен обект с история и стратегическа локация до границата на област Велико Търн ..., тел.: 0889590019&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;55 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ПАРЦЕЛ&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;4974 кв.м, ID:20556 Продава се атрактивен имот с голям понециал в Еленския Балкан разположен в село на 5км гр. ..., тел.: 0878 48 47 40&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;16 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ПАРЦЕЛ&#39;, &#39;location&#39;: &#39;с. Ново село, област Велико Търново&#39;, &#39;info&#39;: &#39;2400 кв.м, Регулация, Предлагаме ЕКСКЛУЗИВНО, дворно място в регулацията на с. Ново село, с площ на парцела 2400кв.м.. Имо ..., тел.: 0878818845&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;65 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава 2-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;57 кв.м, 7-ми ет. от 7, Агенция за недвижими имоти ОНИКС Ви предлага двустаен апартамент в гр. Горна Оряховица, в най-предпо ..., тел.: 0885 971 518&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;67 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава 2-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;60 кв.м, 2-ри ет. от 8, Предлагаме двустаен, панелен апартамент на междинен етаж, с изложение юг. Имота се състои от: коридо ..., тел.: 0878818845&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;70 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава 2-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;68 кв.м, 8-ми ет. от 8, Газ, ДВУСТАЕН АПАРТАМЕНТ ЕКСКЛУЗИВНО ! Агенция за недвижими имоти ОНИКС Ви предлага двустаен панелен апар ..., тел.: 0885 971 518&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;26 300 EUR&#39;, &#39;rooms&#39;: &#39;Продава 3-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;110 кв.м, 1-ви ет. от 3, ЕКСКЛУЗИВНО! Болярски Имоти предлага за продажба изцяло Южен Тристаен апартамент в квартал Гарата гр ..., тел.: 0877559233&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;62 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава 3-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;80 кв.м, 4-ти ет. от 4, Имоти Търновград Ви предлага тристаен апартамент на шпакловка и замазка в тих район на гр. Горна Оря ..., тел.: 0895476397&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;52 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава 4-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;115 кв.м, 5-ти ет. от 5, Ексклузивна оферта! Агенция за имоти продава четиристаен тухлен апартамент в кв.Пролет, близо до пар ..., тел.: 0887999086&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;89 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава 4-СТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#34;170 кв.м, 2-ри ет. от 3, ТЕЦ, Екипът на агенция &#39;ОНИКС&#39; Ви предлага луксозно, обзаведен етаж от къща, находящ се в широкия център ..., тел.: 0885971518&#34;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;52 500 EUR&#39;, &#39;rooms&#39;: &#39;Продава МНОГОСТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;93 кв.м, 1-ви ет. от 4, Имоти Търновград има удоволствието да Ви предложи многостаен тухлен апартамент с гараж в град Горна ..., тел.: 0884796221&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;57 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава МНОГОСТАЕН&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;155 кв.м, 4-ти ет. от 4, Тухла 2011 г., Ексклузивна оферта! Без комисионна за купувача! Продава уникален панорамен ново строителство апартам ..., тел.: 0887999086&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;60 000 лв.&#39;, &#39;rooms&#39;: &#39;Продава ЕТАЖ ОТ КЪЩА&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;100 кв.м, Калтинец, 2-ри ет. от 2, Агенция за недвижими имоти ОНИКС има удоволствието да Ви предложи етаж от къща в град Горна Оряховиц ..., тел.: 0885 971 518&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;92 300 EUR&#39;, &#39;rooms&#39;: &#39;Продава ЕТАЖ ОТ КЪЩА&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;130 кв.м, 1-ви ет. от 2, Агенция за имоти продава ексклузивно луксозно жилище с панорамна гледка в тих и спокоен квартал на Г ..., тел.: 0887999086&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;88 500 лв.&#39;, &#39;rooms&#39;: &#39;Продава ЕТАЖ ОТ КЪЩА&#39;, &#39;location&#39;: &#39;гр. Дебелец, област Велико Търново&#39;, &#39;info&#39;: &#34;89 кв.м, 1-ви ет. от 2, ЕКСКЛУЗИВНО!Екипът на фирма за недвижими имоти &#39;АкцентИ Пропъртис&#39; ООД Ви предлага самостоятелен ета ..., тел.: 0887/573 633&#34;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;65 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава ЕТАЖ ОТ КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;117 кв.м, гр.Елена, 2-ри ет. от 3, Тухла 1978 г., Просторен етаж от масивна двуфамилна къща. Намира се на първи жилищен етаж, над гараж / магазин/ скл ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;43 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Бяла черква, област Велико Търново&#39;, &#39;info&#39;: &#39;130 кв.м, двор 4000 кв.м, 1 ет., Агенция за недвижими имоти БОЛКАН ЕСТЕЙТ предлага ЕКСКЛУЗИВНО на Вашето внимание просторна къща за п ..., тел.: 0886129319&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;55 700 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Горна Оряховица, област Велико Търново&#39;, &#39;info&#39;: &#39;150 кв.м, двор 351 кв.м, Болярски Имоти Ви предлага за продажба САМОСТОЯТЕЛНА двуетажна къща със собствен двор на 5 минути п ..., тел.: 0877559233&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;22 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;214 кв.м, двор 1800 кв.м, с.Беброво, Здрава тухлена двуетажна къща . Сградата е на два етажа, като на първият се намира три стаи, баня и ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;22 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;150 кв.м, двор 620 кв.м, с.Беброво, Здрава тухлена къща с каменни основи. Сградата е на две нива, като на първото се намира магазин, пр ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;25 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;120 кв.м, двор 2530 кв.м, с.Средни Колиби, Къща в блзост до яз. Йовковци. Собствен водоизточник - кладенец, централно водоснабдяване на ВиК, ел ..., тел.: 0887902715&#39;}, {&#39;property_info&#39;: &#39;Обява продава къща, гр. Елена, област Велико Търново&#39;, &#39;price&#39;: &#39;33 000 EUR&#39;, &#39;rooms&#39;: &#39;Продава КЪЩА&#39;, &#39;location&#39;: &#39;гр. Елена, област Велико Търново&#39;, &#39;info&#39;: &#39;90 кв.м, двор 270 кв.м, гр.Елена, Старинна жилищна сграда с дворно място и построената в него двуетажна допълваща сграда. Продава се ж ..., тел.: 0887902715&#39;}] . For example on the first line we may have: (20, 20, 0, 40) - that means that there are 20 properties with &#39;style 0&#39;, 20 properties with &#39;style 1&#39; and 0 properties with &#39;style 2&#39;. The sum of which should be always equal to 40. . The code from above is not hard to understand, but there is a lot of repetition. . I want to explain how to create a DataFrame object and how to translate it into English just to see how this works and then I will amend the code from above and make it more compact. . In the cell below the for loop collects data from multiple pages and saves them on &#39;property_list&#39; variable. . # I overwrite the &#39;property_list&#39; variable to be empty list, # otherwise the &#39;property_list&#39; will grow each time the functions above are run # and will give &#39;wrong&#39; answers when tested property_list = [] for i in range(1,3): print(f&#39;Page number: {i}&#39;) search = extract(i) transform(search) print(len(property_list)) . Page number: 1 Page number: 2 80 . Translation using Google Translate . We have scraped 80 listings from the website, that is now much, but proves that the concept works. . Let&#39;s not forget that the results are in Bulgarian. . The first way to translate into English is to create a Pandas DataFrame object and save the result into a file. Then we can upload the file here: https://translate.google.com/?sl=bg&amp;tl=en&amp;op=translate and translate with Google Translate so we can see the final result. . Initially, when I began working on this project Google Translate was translating *.txt files. . Now it can translate only - .docx, .pdf, .pptx, or .xlsx. . It can not translate *.CSV files as well . First Save it to a *.CSV file to have the right format and to preserve the encoding. . Open the .CSV file &#39;File&#39; -&gt; &#39;Save As&#39; -&gt; &#39;Excel Workbook&#39; (.xlsx). . In that way it will allow us to upload the file to Google Translate. . This will prevent it from telling us that the file is corrupted. . df = pd.DataFrame(property_list) # Print it to see what we got print(df.head()) # Apparently, in the description of each listing we can see many commas and semicolons # that are the usually separators. # It will cause problems, so we can change the separator to be &#39;~&#39; df.to_csv(&#39;test.csv&#39;, encoding = &#39;utf-8-sig&#39;, sep = &#39;~&#39;) . property_info price 0 Обява продава къща, гр. Елена, област Велико Т... 50 000 EUR 1 Обява продава къща, гр. Елена, област Велико Т... 65 000 EUR 2 Обява продава къща, гр. Елена, област Велико Т... 85 000 EUR 3 Обява продава къща, гр. Елена, област Велико Т... 115 000 лв. 4 Обява продава къща, гр. Елена, област Велико Т... 5 999 EUR rooms location 0 Продава КЪЩА гр. Елена, област Велико Търново 1 Продава КЪЩА гр. Елена, област Велико Търново 2 Продава КЪЩА гр. Златарица, област Велико Търново 3 Продава КЪЩА гр. Павликени, област Велико Търново 4 Продава КЪЩА гр. Полски Тръмбеш, област Велико Търново info 0 146 кв.м, двор 2200 кв.м, с.Дърлевци, Реновира... 1 144 кв.м, двор 739 кв.м, с.Граматици, Атрактив... 2 185 кв.м, двор 613 кв.м, Primo+ Велико Търново... 3 123 кв.м, двор 750 кв.м, Имоти Търновград Ви п... 4 140 кв.м, двор 3000 кв.м, село Орловец, Тухлен... . I had to manually delete the first row of the file - &#39;test_after_translation&#39; (Excel Worksheet), then save it to &#39;test_after_translation&#39; (.CSV). Now when I read the .CSV file in Python I wouldn&#39;t get an error about some rows having more elements than others, then as you can see below I added again the column names so no harm done. . # We have to make sure that all the rows are translated and not just partly. # If the file has been translated partly then we can try again until it is fully translated. translated_df = pd.read_csv(&#39;./test_after_translation.csv&#39;, sep = &#39;~&#39;, header = None) translated_df = translated_df.drop(axis = 1, columns = 0) translated_df.columns = [&#39;property_info&#39;, &#39;price&#39;, &#39;rooms&#39;, &#39;location&#39;,&#39;info&#39;] translated_df.head() . property_info price rooms location info . 0 Ad for sale house, town of Elena, Veliko Tarn... | 50 000 EUR | House for sale | c. Helen, Veliko Tarnovo region | 146 sq.m., yard 2200 sq.m., The village of Da... | . 1 Ad sells a house, town of Elena, Veliko Tarno... | 65 000 EUR | House for sale | c. Helen, Veliko Tarnovo region | 144 sq.m., yard 739 sq.m., Gramatici village,... | . 2 Ad for sale house, town of Elena,Veliko Tarno... | 85 000 EUR | House for sale | c. Zlataritsa, Veliko Tarnovo region | 185 sq.m., yard 613 sq.m., Primo + Veliko Tar... | . 3 Ad for sale house, town of Elena, Veliko Tarn... | 115 000 BGN | HOUSE FOR SALE | c. Pavlikeni, Veliko Tarnovo region | 123 sq.m., yard 750 sq.m., Property Tarnovgra... | . 4 Ad sells a house, town of Elena,Veliko Tarnov... | 5 999 EUR | House for sale | c. Polski Trambesh, Veliko Tarnovo region | 140 sq.m., yard 3000 sq.m., the village of Or... | . The above DataFrame is the result I got. . . . Now let&#39;s try the other way to translate the Bulgarian DataFrame we managed to scrape. . For this purpose we will use &#39;google_trans_new&#39; module. . Important: There is a bug we need to fix before translating anything. . https://github.com/lushan88a/google_trans_new/issues/36 . Change line 151 and line 233 in google_trans_new/google_trans_new.py: . response = (decoded_line + &#39;]&#39;) TO response = (decoded_line) . Translation using &#39;google_trans_new&#39; module . def basic_translation(text_for_translation, target_language): &#39;&#39;&#39; Basic function introducing &#39;google_trans_new&#39;. &#39;&#39;&#39; # We instantiate &#39;google_translator&#39; object called &#39;translator&#39; translator = google_translator(url_suffix=&quot;bg&quot;, timeout=5) # In the brackets we put the text we need translated first, then we define &#39;lang_tgt&#39; parameter # that is used to tell to what language we need to translate the original text translate = translator.translate(text_for_translation, lang_tgt = target_language, pronounce = True) return print(translate) basic_translation(&#39;สวัสดีจีน&#39;, &#39;zh&#39;) # &#39;zh&#39; is for Chinese basic_translation(&#39;Привет мир&#39;, &#39;en&#39;) basic_translation(&#39;Здравей свят&#39;, &#39;en&#39;) . [&#39;你好中文 &#39;, &#39;S̄wạs̄dī cīn&#39;, &#39;Nǐ hǎo zhōngwén&#39;] [&#39;Hello World &#39;, &#39;Privet mir&#39;, None] [&#39;Hello world &#39;, &#39;Zdraveĭ svyat&#39;, None] . Now we can try to translate the DataFrame from above directly without having to save files and manually translate them with Google. . It might take some time to complete the translation process. . def google_trans(dataframe, source_language, target_language): &#39;&#39;&#39; Simple function for translating a DataFrame. &#39;&#39;&#39; # We instantiate &#39;google_translator&#39; object called &#39;translator&#39; translator = google_translator(url_suffix=&quot;bg&quot;, timeout=5) # Creating a deep copy of the dataframe google_df = dataframe.copy(deep = True) # Instantiating &#39;columns&#39; variable to store the names of the columns columns = google_df.columns # For-looping through each column and overwriting each text with translated text for column in columns: google_df[column] = google_df[column].apply(translator.translate, lang_src = source_language, lang_tgt = target_language) return google_df . Translating the DataFrame and saving it into file. . google_trans_df = google_trans(df, &#39;bg&#39;, &#39;en&#39;) google_trans_df.to_csv(&#39;google_trans_test.csv&#39;) . Reading from the saved file. . google_trans_df = pd.read_csv(&#39;./google_trans_test.csv&#39;) google_trans_df = google_trans_df.drop(axis = 1, columns = &#39;Unnamed: 0&#39;) . Comparing the results from the translation . Finally, lets compare the results. . First the Original Dataframe followed by the Manually translated DataFrame and third will be the &#39;Google Trans New&#39; DataFrame. . df.head(3) . property_info price rooms location info . 0 Обява продава къща, гр. Елена, област Велико Т... | 50 000 EUR | Продава КЪЩА | гр. Елена, област Велико Търново | 146 кв.м, двор 2200 кв.м, с.Дърлевци, Реновира... | . 1 Обява продава къща, гр. Елена, област Велико Т... | 65 000 EUR | Продава КЪЩА | гр. Елена, област Велико Търново | 144 кв.м, двор 739 кв.м, с.Граматици, Атрактив... | . 2 Обява продава къща, гр. Елена, област Велико Т... | 85 000 EUR | Продава КЪЩА | гр. Златарица, област Велико Търново | 185 кв.м, двор 613 кв.м, Primo+ Велико Търново... | . translated_df.head(3) . property_info price rooms location info . 0 Ad for sale house, town of Elena, Veliko Tarn... | 50 000 EUR | House for sale | c. Helen, Veliko Tarnovo region | 146 sq.m., yard 2200 sq.m., The village of Da... | . 1 Ad sells a house, town of Elena, Veliko Tarno... | 65 000 EUR | House for sale | c. Helen, Veliko Tarnovo region | 144 sq.m., yard 739 sq.m., Gramatici village,... | . 2 Ad for sale house, town of Elena,Veliko Tarno... | 85 000 EUR | House for sale | c. Zlataritsa, Veliko Tarnovo region | 185 sq.m., yard 613 sq.m., Primo + Veliko Tar... | . google_trans_df.head(3) . property_info price rooms location info . 0 Listing House for sale, Elena, Veliko Tarnovo ... | EUR 50 000 | House for sale | Elena, Veliko Tarnovo District | 146 sq.m, yard 2200 sq.m, S.Mrulevtsi, renovat... | . 1 Listing House for sale, Elena, Veliko Tarnovo ... | EUR 65 000 | House for sale | Elena, Veliko Tarnovo District | 144 sq.m, yard 739 sq.m, villageGamatsi, attra... | . 2 Listing House for sale, Elena, Veliko Tarnovo ... | 85 000 EUR | House for sale | Zlataritsa, Veliko Tarnovo region | 185 sq.m, yard 613 sq.m, Primo + Veliko Tarnov... | . Overall, both translations are good, both have flaws and good sides, but personally I prefer the Manual translation : &#39;translated_df&#39; . Now we can upgrade the code and scrape listings from multiple municipalities. . . . Introducing new ideas and code modification . Might be useful to see how we can get the last page for this website. . Keep in mind every website is designed differently and the code below will not work with other websites. The way I found the last page number was to find the text representing it in the HTML code. . span class=&quot;pageNumbersInfo&quot;&gt;&#1057;&#1090;&#1088;&#1072;&#1085;&#1080;&#1094;&#1072; 1 &#1086;&#1090; 25&lt;/span . Translated: span class=&quot;pageNumbersInfo&quot;&gt;PAGE 1 OF 25&lt;/span . It is interesting to mention that this website has 25 pages of properties for each municipality and each page has 40 property listings. . def transform_page_number(soup): &#39;&#39;&#39; This simple function is used to find the last page number for each municipality. Assumes that the page number is 2 digit number &#39;&#39;&#39; # We are looking for &#39;span&#39; tag from class &#39;pageNumbersInfo&#39; last_page = soup.find(&#39;span&#39;, class_ = &#39;pageNumbersInfo&#39;).text.strip()[-2:] last_page_number.append(last_page) return last_page_number # we create empty list to which we append info property_list = [] last_page_number = [] search = extract(1) print(transform_page_number(search)) . [&#39;25&#39;] . . In order to get results from multiple municipalities we need to alter the code for the &#39;extract&#39; function. The code for &#39;transform&#39; function stays the same, it is not the best code. We can see repetition occuring. . The &#39;modified_extract&#39; function takes another argument called &#39;municipality&#39; that is the code of the municipality from the URL for it. We will use it instead of &#39;extract&#39; from now on. . def modified_extract(page, municipality): &#39;&#39;&#39; This function is used to change the number of the page from the link. So after we finish with collecting the data from page 1, we can continue to page 2 of that webpage and so on. &#39;&#39;&#39; # https://router-network.com/tools/what-is-my-user-agent -&gt; to find the &#39;user agent&#39; # or google -&gt; &#39;what is my user agent&#39; # &#39;user agent&#39; is a mediator between the user and the internet it holds technical information # about the device (the computer used) and the software # the &#39;user agent&#39; is unique for every person on the internet headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36&#39;} # f-string in which we can change the number of the page # note that &#39;page&#39; in the f-string is the parameter of the function # in addition to that now we can input diferent strings that represent minicipalities url = f&#39;https://www.imot.bg/pcgi/imot.cgi?act=3&amp;slink={municipality}&amp;f1={page}&#39; r = requests.get(url, headers) soup = BeautifulSoup(r.content, &#39;html.parser&#39;) return soup . def transform(soup): &#39;&#39;&#39; This function is used to find and collect information. &#39;&#39;&#39; # We can find all &#39;div&#39; tags that store the price of each property listing # in that way we can get all 40 listings price_div = soup.find_all(&#39;div&#39;, class_ = &#39;price&#39;) # Each listing is associated with a particular style that actually shows if the listing # is &#39;Top&#39;, &#39;Vip&#39; or just ordinary listing style_0 = &quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/top_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot; style_1 = &quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/vip_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot; style_2 = &quot;margin-bottom:0px; border-top:#990000 1px solid;&quot; # We locate all tags &#39;table&#39; that contain all the information we can scrape and we associate # the &#39;table&#39; tag with the different styles table_0 = soup.find_all(&#39;table&#39;, style=style_0) table_1 = soup.find_all(&#39;table&#39;, style=style_1) table_2 = soup.find_all(&#39;table&#39;, style=style_2) # The following three for loops go through each &#39;table&#39; tag and scrape information from it # The each for loop stores the information into a dictionary. Each dictionary is then appended # to a list that contains all the information. for i in table_0: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_0 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_0) for i in table_1: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_1 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_1) for i in table_2: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = i.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = i.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = i.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = i.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary_2 = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary_2) return len(table_0), len(table_1), len(table_1), len(price_div) # we create empty list to which we append the information gathered from the three for loops property_list = [] # These are two list variables that store strings for the municipality and # the actual name of the municipality municipality = [&#39;7o9q5q&#39;, &#39;7o9q7x&#39;] municipality_translation = [&#39;Veliko Tarnovo&#39;, &#39;Sofia City&#39;] # For loop that does the web scraping for i in range(len(municipality)): x = municipality[i] for j in range(1,3): print(f&#39;Page number: {j} - {municipality_translation[i]}&#39;) search = modified_extract(j,x) transform(search) print(len(property_list)) . Page number: 1 - Veliko Tarnovo Page number: 2 - Veliko Tarnovo Page number: 1 - Sofia City Page number: 2 - Sofia City 160 . What is important is that we have managed to extract all the property listings of two pages for two municipalities. That means that we can scrape all the property listings if we just add the code for each municipality to the list &#39;municipality&#39;. In addition to that we can see that for the four pages that we scraped the sum of listings is equal to 160, which means that all is working as it should. . What is left to do is to make the code for the &#39;transform&#39; function more compact and to reduce the amount of code. In that way we will reduce the repetition and improve the quality of the code. . def modified_transform(soup): # finds the total number of pages # assumes that the page number is 2 digit number # span class=&quot;pageNumbersInfo&quot;&gt;Страница 1 от 25&lt;/span&gt; - Page 1 of 25 last_page = soup.find(&#39;span&#39;, class_ = &#39;pageNumbersInfo&#39;).text.strip()[-2:] last_page_number.append(int(last_page)) # We can find all &#39;div&#39; tags that store the price of each property listing # in that way we can get all 40 listings price_div = soup.find_all(&#39;div&#39;, class_ = &#39;price&#39;) # Each listing is associated with a particular style that actually shows if the listing # is &#39;Top&#39;, &#39;Vip&#39; or just ordinary listing styles = [&quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/top_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot;, &quot;margin-bottom:0px; border-top:#990000 1px solid; background:url(../images/picturess/vip_bg.gif); background-position:bottom; background-repeat:repeat-x;&quot;, &quot;margin-bottom:0px; border-top:#990000 1px solid;&quot;] # The &#39;table&#39; tags that contain the information do not have class, the only way to distinguish # one from another is the &#39;style&#39; attribute that they have # We can create a for loop that will collect automatically all the information instead repeating # the process three times for each table style and if something is changed we can easily # amend where it is needed. for i in range(len(styles)): table_x = soup.find_all(&#39;table&#39;, style=styles[i]) for j in table_x: property_info = soup.find(&quot;a&quot;, class_ = &#39;photoLink&#39;).img.get(&#39;alt&#39;).strip() price = j.find(&#39;div&#39;, class_ = &#39;price&#39;).text.strip() rooms = j.find(&#39;a&#39;, class_ = &#39;lnk1&#39;).text.strip() location = j.find(&#39;a&#39;, class_ = &#39;lnk2&#39;).text.strip() info = j.find(&#39;td&#39;, width=&quot;520&quot;, colspan=&quot;3&quot;, height=&quot;50&quot;, style=&quot;padding-left:4px&quot;).text.strip() # dictionary to store the collected information property_dictionary = { &#39;property_info&#39; : property_info, &#39;price&#39; : price, &#39;rooms&#39; : rooms, &#39;location&#39; : location, &#39;info&#39; : info } property_list.append(property_dictionary) return len(price_div), last_page_number[0], len(property_info) # we create empty list to which we append info property_list = [] # variable to store the the last page number last_page_number = [] # FOR INFORMATION # The URL code for each municipality is different every now and again. # This is just an example on how to collect them. # Keep in mind that those codes have expired and will give error, # because it can not find the page number if the municipality code from the URL is changed. # municipality = [&#39;7gf7vh&#39;, &#39;7gk4sj&#39;, &#39;7gjb7j&#39;, &#39;7gjay6&#39;, &#39;7gk56o&#39;, &#39;7gk4gh&#39;] # municipality_translation = [&#39;Veliko Tarnovo&#39;, &#39;Sofia City&#39;, &#39;Sofia Municipality&#39;, # &#39;Lovetch&#39;, &#39;Burgas&#39;, &#39;Varna&#39;] # You can see that at the moment &#39;Veliko Tarnovo&#39; code is &#39;7lzaba&#39; and not &#39;7gf7vh&#39;. municipality = [&#39;7o9q5q&#39;] municipality_translation = [&#39;Veliko Tarnovo&#39;] # In order to get the last page number we need to run &#39;modified_extract&#39; function once # so we can get the value of &#39;last_page_number&#39; variable and empty the &#39;property_list&#39; variable # For information - it turns out that this site has only 25 pages with 40 properties # per page for each municipality search = modified_extract(1, &#39;7o9q5q&#39;) modified_transform(search) # #print(transform(search)) property_list = [] . The following cell contains two identical in what they do for loops. The difference between them is that the first one finds the last page number, where as the second one has the number hard-coded. . property_list = [] for i in range(len(municipality)): for j in range(0, int(last_page_number[0])): print(f&#39;Page number: {j} - {municipality_translation[i]}&#39;) search = modified_extract(j, municipality[i]) modified_transform(search) # This is the same for-loop as the one from above, it is just using out knowledge that the last page number is 25. # for i in range(len(municipality)): # for j in range(1, 26, 1): # print(f&#39;Page number: {j} - {municipality_translation[i]}&#39;) # search = modified_extract(j, municipality[i]) # transform(search) print(len(property_list)) print(last_page_number) . Page number: 0 - Veliko Tarnovo Page number: 1 - Veliko Tarnovo Page number: 2 - Veliko Tarnovo Page number: 3 - Veliko Tarnovo Page number: 4 - Veliko Tarnovo Page number: 5 - Veliko Tarnovo Page number: 6 - Veliko Tarnovo Page number: 7 - Veliko Tarnovo Page number: 8 - Veliko Tarnovo Page number: 9 - Veliko Tarnovo Page number: 10 - Veliko Tarnovo Page number: 11 - Veliko Tarnovo Page number: 12 - Veliko Tarnovo Page number: 13 - Veliko Tarnovo Page number: 14 - Veliko Tarnovo Page number: 15 - Veliko Tarnovo Page number: 16 - Veliko Tarnovo Page number: 17 - Veliko Tarnovo Page number: 18 - Veliko Tarnovo Page number: 19 - Veliko Tarnovo Page number: 20 - Veliko Tarnovo Page number: 21 - Veliko Tarnovo Page number: 22 - Veliko Tarnovo Page number: 23 - Veliko Tarnovo Page number: 24 - Veliko Tarnovo 1000 [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25] . We got 25 pages, which is the total amount and 25 times 40 is equal to 1000 and that is the exact number of property listings that we got. . We can just add more municipalities and to the &#39;municipality&#39; list and it will collect all the data for us. . Then we can save the dataframe as shown before as CSV file and read the CSV into Pandas to start cleaning and analyzing the data. . Lastly, I want to show that it can work for different municipalities, but I will hard code it to take the first 2 pages of each so it will show that it can do the job as it should. . municipality = [&#39;7o9qpr&#39;, &#39;7o9q5q&#39;, &#39;7o9qs2&#39;] municipality_translation = [&#39;Sofia City&#39;, &#39;Veliko Tarnovo&#39;, &#39;Varna&#39;] last_page_number = [] property_list = [] for i in range(len(municipality)): # for j in range(0, int(last_page_number[0])): for j in range(0, 2): print(f&#39;Page number: {j} - {municipality_translation[i]}&#39;) search = modified_extract(j, municipality[i]) modified_transform(search) print(len(property_list)) print(last_page_number) . Page number: 0 - Sofia City Page number: 1 - Sofia City Page number: 0 - Veliko Tarnovo Page number: 1 - Veliko Tarnovo Page number: 0 - Varna Page number: 1 - Varna 240 [25, 25, 25, 25, 25, 25] . We can still check the results and make sure that everything is working fine. 6 * 40 = 240. That is obvious, but let&#39;s check what are the municipality names. . # this one doesn&#39;t have the pronunciation written down, which we do not need. def basic_translation_list(text_for_translation, target_language): &#39;&#39;&#39; Basic function introducing &#39;google_trans_new&#39;. &#39;&#39;&#39; # We instantiate &#39;google_translator&#39; object called &#39;translator&#39; translator = google_translator(url_suffix=&quot;bg&quot;, timeout=5) # In the brackets we put the text we need translated first, then we define &#39;lang_tgt&#39; parameter # that is used to tell to what language we need to translate the original text translate = translator.translate(text_for_translation, lang_tgt = target_language) return print(translate) def dictionary_into_dataframe(dictionary): &#39;&#39;&#39; This function takes as an argument a dictionary and creates a DataFrame using Pandas. The function returns as a result the municipalities. &#39;&#39;&#39; # We instantiate a DataFrame object dataframe = pd.DataFrame(dictionary) # We take only the &#39;location&#39; column for translation dataframe_unique_locations = dataframe[&#39;location&#39;].unique() # The actual translation translation = basic_translation_list(dataframe_unique_locations, &#39;en&#39;) return translation . dictionary_into_dataframe(property_list) . [&#39;city Sofia, Banishora&#39; &#39;city Sofia, Vitosha&#39; &#39;city Sofia, Vrabnitsa 1&#39; &#39;city of Sofia, Geo Milev&#39; &#39;city Sofia, Dianabad&#39; &#39;city Sofia, Dragalevtsi&#39; &#39;city of Sofia, Darvenica&#39; &#39;city Sofia, Lozenets&#39; &#39;city Sofia, Lyulin 5&#39; &#39;city of Sofia, Lyulin 7&#39; &#39;city Sofia, Malinova Valley&#39; &#39;city of Sofia, Manastirski livadi&#39; &#39;city Sofia, Mladost 1&#39; &#39;city of Sofia, Mladost 3&#39; &#39;city Sofia, Mladost 4&#39; &#39;city of Sofia, modern suburb&#39; &#39;city Sofia, Hope 1&#39; &#39;city of Sofia, Obelya 2&#39; &#39;city Sofia, Ovcha Kupel 1&#39; &#39;city Sofia, Pavlovo&#39; &#39;city of Sofia, Poduyane&#39; &#39;city Sofia, the Holy Trinity&#39; &#39;city Sofia, Slatina&#39; &#39;city. Elena, Veliko Tarnovo region &#39;&#39; gr. Zlataritsa, Veliko Tarnovo region &#39;city. Pavlikeni, Veliko Tarnovo region &#39;city. Polski Trambesh, Veliko Tarnovo region &#39;s. Balvan, Veliko Tarnovo region &#39;&#39; s. Bridkovtsi, Veliko Tarnovo region &#39;s. Julyunitsa, Veliko Tarnovo region &#39;s. The camps, Veliko Tarnovo region Ledenik, Veliko Tarnovo region &#39;s. Lesichari, Veliko Tarnovo Region &#39;&#39; Pales, Veliko Tarnovo Region &#39;s. Samepage, Veliko Tarnovo Region &#39;s. Hotnitsa, Veliko Tarnovo region &#34; Novo selo, Veliko Tarnovo region &#39;city. Gorna Oryahovitsa, Veliko Tarnovo region &#39;city. Debelets, Veliko Tarnovo region &#39;city. White church, Veliko Tarnovo region &#34; Byala, Varna Region &#39;kk Kamchia, Varna Region &#39;&#39; Valchi Dol, Varna Region &#39; &#39;city. Provadia, Varna Region &#39;&#39; s. Avren, Varna Region &#39; &#39;s. Gemini, Varna Region &#39;&#39; s. Bolagers, Varna Region &#39; &#39;s. General Kantardzhievo, Varna Region &#34; Oreshak, Varna Region &#39; &#39;s. Radevo, Varna Region &#39;&#39; Shkorpilovtsi, Varna Region &#39; &#39;s. Goritsa, Varna Region &#34;s. Chertricks, Varna Region &#39; &#39;city. Beloslav, Varna Region &#39;] . If we take a second and look at the result we have from the cell below we can see that the municipalities listed below are as follows: &#39;city of Sofia&#39;, &#39;Veliko Tarnovo region&#39; and &#39;Varna Region&#39;. That means that the Web scraper is doing exactly what we want. . The main task that we have specified in the beginning of this Jupyter Notebook is now accomplished. That doesn&#39;t mean that we still do not have work to do for the data that we have extracted, but this is for another Jupyter Notebook. . Thank you very much for your attention and time. . Kind regards, . Mladen . .",
            "url": "https://mrt5010v.github.io/Fastpages-Portfolio/data%20science/data%20engineering/web%20scraper/beautiful%20soup/translation/2022/03/18/Web-Scraping-Property-Listings-Project.html",
            "relUrl": "/data%20science/data%20engineering/web%20scraper/beautiful%20soup/translation/2022/03/18/Web-Scraping-Property-Listings-Project.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Data Science Project For Properties - Cleaning, Visualization on a Real Map, Average Price Property Finder and a Pinch of Machine Learning",
            "content": "The price of a property depends on many indicators, some of them are: location, size, amenities, access to facilities and many more. In this Jupyter Notebook you can see how I managed to find an average price of a house in a given address. . In the following Jupyter Notebook link you can see the code and interactive visualizations. . Because the visualizations do not load properly here please use the following link below. . It will use my repository in Github and will generate the project: . https://nbviewer.org/github/mrt5010v/Data-Science-Project-For-Finding-Property-Prices/blob/main/Approximate%20house%20price%20finder.ipynb . You can modify the code with Binder as well .",
            "url": "https://mrt5010v.github.io/Fastpages-Portfolio/data%20science/data%20visualization/data%20tidying%20and%20cleaning/pandas/folium/k-nn/machine%20learning/2022/03/18/Data-Science-Project-For-Finding-Property-Prices-portfolio.html",
            "relUrl": "/data%20science/data%20visualization/data%20tidying%20and%20cleaning/pandas/folium/k-nn/machine%20learning/2022/03/18/Data-Science-Project-For-Finding-Property-Prices-portfolio.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Working with Files Using Python, Pandas and SQLite3",
            "content": "Let&#39;s begin with the imports. . import sqlite3 as sql import csv import os import stat import os.path import glob from collections import Counter import re import pandas as pd import numpy as np import matplotlib.pyplot as plt import shutil from time import gmtime, strftime # The two lines below allow us to see all the columns without truncation. # It allows us to see the dataset better. pd.options.display.max_columns = None pd.options.display.max_rows = None . . First of all I want to join the path and the files inside of the &#39;sample_data&#39; folder. . def path_merger(file_directory_path): &#39;&#39;&#39; This function merges the &#39;file_directory_path&#39; path with the files inside of the folder. Returns the number of the files found in the directory. &#39;&#39;&#39; # We assign &#39;file_dir&#39; variable to be string with the path to the sample data files. file_dir = file_directory_path # Merges the sample data folder path with the file name. file_list = [os.path.join(file_dir, file) for file in os.listdir(file_dir)] return file_list . try: file_list = path_merger(&#39;./sample_data/&#39;) except FileNotFoundError as err: print(&#39;FileNotFoundError: [WinError 3] The system cannot find the specified path. Please try again.&#39;) . We can see the result of the function &#39;path_merger&#39; in the sliced variable &#39;file_list&#39; below. . file_list[:3] . [&#39;./sample_data/PN000001.SMRT&#39;, &#39;./sample_data/PN000002.SMRT&#39;, &#39;./sample_data/PN000003.SMRT&#39;] . len(file_list) . 12 . Next we need to check if the files are complete. In other words we can check if the files have the both keywords (&#39;HEADR&#39; and &#39;TRAIL&#39;). If the files have both of the keywords a copy of them is made in other folder. . As an example we can see in the cell below the number of keywords each file has. . For functionallity check I added a file called &#39;PN000012&#39; without &#39;TRAIL&#39; keyword and another file called &#39;PN000011&#39; both of the files are copy of &#39;PN000010&#39;. . # This for loop is counting the &#39;keywords&#39; in the files counter_for_the_files = [] for i in range(len(file_list)): with open(file_list[i], &#39;r&#39;, encoding=&#39;utf-8&#39;) as file: key_words = [&#39;HEADR&#39;, &#39;TRAIL&#39;] key_word_counter = 0 for line in file: for word in key_words: if word in line: key_word_counter += 1 counter_for_the_files.append(str(i) + &#39; - &#39; + str(key_word_counter)) counter_for_the_files . [&#39;0 - 2&#39;, &#39;1 - 2&#39;, &#39;2 - 2&#39;, &#39;3 - 2&#39;, &#39;4 - 2&#39;, &#39;5 - 2&#39;, &#39;6 - 2&#39;, &#39;7 - 2&#39;, &#39;8 - 2&#39;, &#39;9 - 2&#39;, &#39;10 - 2&#39;, &#39;11 - 1&#39;] . def function_that_finds_the_complete_files_and_saves_a_copy(list_of_files): &#39;&#39;&#39; This function finds the number of the files that have two &#39;keywords&#39; (complete files) - &#39;HEADR&#39; and &#39;TRAIL&#39;. Furthermore, it will separate the files that passed the check in other folder. In that way we can work with complete files. &#39;&#39;&#39; counter_for_the_files = [] # This for loop collects the number of the file that has both &#39;keywords&#39;. for i in range(len(file_list)): with open(list_of_files[i], &#39;r&#39;, encoding=&#39;utf-8&#39;) as file: key_words = [&#39;HEADR&#39;, &#39;TRAIL&#39;] key_word_counter = 0 for line in file: for word in key_words: if word in line: key_word_counter += 1 if key_word_counter == 2: counter_for_the_files.append(i) else: pass counter_for_the_files # The only thing that we need to do manually is to create the folder, where we will store the files: &#39;pandas_data&#39; # We copy the files that pass the initial test so we can remove the keywords for i in range(len(counter_for_the_files)): # If the file is in the list, then it means that the file is complete and we do want to use it. if i in counter_for_the_files: shutil.copyfile(list_of_files[i], &#39;./pandas_data/&#39; + str(list_of_files[i][14:22]) + &#39;_copy.SMRT&#39;) # If the file doesn&#39;t have both of the keywords we want to remove them. else: pass return counter_for_the_files . function_that_finds_the_complete_files_and_saves_a_copy(file_list) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] . As we can see the number of files is 11, which means that we have removed the one which is not complete. . Next we use the function we defined earlier to join the path and the copied files that have passed the requirement. . try: pandas_file_dir = path_merger(&#39;./pandas_data/&#39;) except FileNotFoundError as err: print(&#39;FileNotFoundError: [WinError 3] The system cannot find the specified path. Please try again.&#39;) . We can start the cleaning process. . The following code removes the keywords mentioned earlier, we can leave them in or remove them the cell below is optional. . But we will not delete the main files, that will ruin the data that we collected. We need to save the new files in a new folder that will contain only data that is reliable and it can be loaded straight to &#39;Pandas&#39; for additional work. . def key_words_cleaner(filtered_file_list): &#39;&#39;&#39; This function is optional it deletes the keywords of the copy we have saved. Opens to read all the files and replaces the items of the list with empty strings and saves it to empty list &#39;text&#39; and then writes the contents of &#39;text&#39; to the already read file. &#39;&#39;&#39; for i in range(len(filtered_file_list)): with open(filtered_file_list[i], &#39;r&#39;, encoding=&#39;utf-8&#39;) as file: key_words = [&#39;HEADR&#39;, &#39;TRAIL&#39;] text = [] for line in file: for word in key_words: line = line.replace(word, &#39;&#39;) text.append(line) with open(filtered_file_list[i], &#39;w+&#39;, encoding=&#39;utf-8&#39;) as file: for line in text: file.write(line) . key_words_cleaner(pandas_file_dir) . Now we can proceed with the editing using Pandas. . def preliminary_pandas_editor(filtered_file_list): &#39;&#39;&#39; This function does initial preparation for the data. &#39;&#39;&#39; for i in range(len(filtered_file_list)): # We can skip the footer, because it is full of &#39;NaN&#39;-s, clear the header. dataframe = pd.read_csv(filtered_file_list[i], skipfooter = 1, header = None, engine = &#39;python&#39;) # Give proper names to the columns. dataframe.columns = [&#39;record_identifier&#39;, &#39;meter_number&#39;, &#39;measurement_date&#39;, &#39;measurement_time&#39;, &#39;consumption&#39;, &#39;table_info&#39;] # Creating new columns with information taken from the first &#39;HEADR&#39; row. dataframe[[&#39;file_type_identifier&#39;]] = str(dataframe[&#39;meter_number&#39;].iloc[0]) dataframe[[&#39;company_id&#39;]] = str(dataframe[&#39;measurement_date&#39;].iloc[0]) dataframe[[&#39;file_creation_date&#39;]] = str(dataframe[&#39;measurement_time&#39;].iloc[0]) dataframe[[&#39;file_creation_time&#39;]] = str(dataframe[&#39;consumption&#39;].iloc[0])[:-2] dataframe[[&#39;file_generation_number&#39;]] = str(dataframe[&#39;table_info&#39;].iloc[0]) dataframe[&#39;measurement_time&#39;] = dataframe[&#39;measurement_time&#39;].astype(object) dataframe[&#39;measurement_date&#39;] = dataframe[&#39;measurement_date&#39;].astype(object) dataframe[&#39;file_creation_date&#39;] = dataframe[&#39;file_creation_date&#39;].astype(object) dataframe[&#39;file_creation_time&#39;] = dataframe[&#39;file_creation_time&#39;].astype(object) # We can delete the first row because we got the info from it assigned to new columns. dataframe.drop(labels = 0, axis = 0, inplace = True) # We can delete this column, it is empty and we don&#39;t need it. dataframe.drop([&#39;table_info&#39;], axis = 1, inplace = True) dataframe.to_csv(filtered_file_list[i], encoding=&#39;utf-8&#39;) . preliminary_pandas_editor(pandas_file_dir) . We can see an example of what we have done so far. . test_1 = pd.read_csv(pandas_file_dir[0], index_col = &#39;Unnamed: 0&#39;) . test_1.head() . record_identifier meter_number measurement_date measurement_time consumption file_type_identifier company_id file_creation_date file_creation_time file_generation_number . 1 CONSU | 2 | 20191014 | 1100 | 10.28 | SMRT | GAZ | 20191016 | 102939 | PN000001 | . 2 CONSU | 2 | 20191014 | 1200 | 2.84 | SMRT | GAZ | 20191016 | 102939 | PN000001 | . 3 CONSU | 2 | 20191014 | 1300 | 14.65 | SMRT | GAZ | 20191016 | 102939 | PN000001 | . 4 CONSU | 2 | 20191014 | 1400 | 11.69 | SMRT | GAZ | 20191016 | 102939 | PN000001 | . 5 CONSU | 2 | 20191014 | 1500 | 14.02 | SMRT | GAZ | 20191016 | 102939 | PN000001 | . The function earlier that made a copy of the files might have copied files with the same name. The following code removed any repetition. . The cell below shows an example, where we have copy of &#39;PN000010&#39;. . list_for_checking_repeating = [] for i in range(len(pandas_file_dir)): dataframe = pd.read_csv(pandas_file_dir[i], index_col = &#39;Unnamed: 0&#39;) list_for_checking_repeating.append(dataframe[&#39;file_generation_number&#39;].iloc[0]) list_for_checking_repeating . [&#39;PN000001&#39;, &#39;PN000002&#39;, &#39;PN000003&#39;, &#39;PN000004&#39;, &#39;PN000005&#39;, &#39;PN000006&#39;, &#39;PN000007&#39;, &#39;PN000008&#39;, &#39;PN000009&#39;, &#39;PN000010&#39;, &#39;PN000010&#39;] . def repetition_remover(filtered_file_list): &#39;&#39;&#39; Removes the duplicate files from the copy folder. &#39;&#39;&#39; # As per the cell above this list variable stores all the files in the copy folder. list_for_checking_repeating = [] # &#39;new list&#39; is used to store the new list without repetitions. new_list = [] # We fill the list with the file names. for i in range(len(pandas_file_dir)): dataframe = pd.read_csv(pandas_file_dir[i], index_col = &#39;Unnamed: 0&#39;) list_for_checking_repeating.append(dataframe[&#39;file_generation_number&#39;].iloc[0]) # Search for the name of the repeating file. repeat = [item for item, count in Counter(list_for_checking_repeating).items() if count &gt; 1] repeating_files = [] # Searching for the number of the repeating file in the folder. for i in range(len(pandas_file_dir)): dataframe = pd.read_csv(pandas_file_dir[i], index_col = &#39;Unnamed: 0&#39;) if dataframe[&#39;file_generation_number&#39;].iloc[0] == repeat[0]: repeating_files.append(i) os.remove(pandas_file_dir[repeating_files[1]]) return repeating_files, repeat[0] . repetition_remover(pandas_file_dir) . ([9, 10], &#39;PN000010&#39;) . After deleting the repeating file we need to refresh the variable &#39;pandas_file_dir&#39;. . try: pandas_file_dir = path_merger(&#39;./pandas_data/&#39;) except FileNotFoundError as err: print(&#39;FileNotFoundError: [WinError 3] The system cannot find the specified path. Please try again.&#39;) . len(pandas_file_dir) . 10 . The file with repeating data was successfully removed. If we run the whole program and open at the same time the folder &#39;pandas_data&#39; we can see the whole process happening infront of us. . . The next step we can do is to convert the date and time columns to datetime column. . def columns_to_dateframe_column(filtered_file_list, date_column, time_column, new_column_name): &#39;&#39;&#39; !!! WARNING !!! Because this function modifies the dataframe, we must run it only once. If run twice error will appear. This function converts &#39;time&#39; and &#39;date&#39; columns from a &#39;dataframe&#39; to a new &#39;datetime&#39; column. Depending on the needs we might have to remove the initial &#39;date_column&#39; and &#39;time_column&#39;, which will be replaced by &#39;new_column_name&#39;. &#39;&#39;&#39; for i in range(len(filtered_file_list)): # We can skip the footer, because it is full of &#39;NaN&#39;-s, clear the header. dataframe = pd.read_csv(filtered_file_list[i], index_col = &#39;Unnamed: 0&#39;) #&#39;SettingWithCopyWarning&#39; warning pops up and tells us that &#39;A value is trying to be set on a copy of a # slice from a DataFrame&#39;. # We can ignore this warning, because we have the main data in other folder. # The first line below deactivates &#39;SettingWithCopyWarning&#39;, which is not useful in our case. pd.set_option(&#39;mode.chained_assignment&#39;, None) # Adds zeros to reach the proper number of values. for j in range(len(dataframe)): if len(str(dataframe[time_column].iloc[j])) == 1: dataframe[time_column].iloc[j] = &#39;000&#39; + str(dataframe[time_column].iloc[j]) + &#39;00&#39; elif len(str(dataframe[time_column].iloc[j])) == 2: dataframe[time_column].iloc[j] = &#39;00&#39; + str(dataframe[time_column].iloc[j]) + &#39;00&#39; elif len(str(dataframe[time_column].iloc[j])) == 3: dataframe[time_column].iloc[j] = &#39;0&#39; + str(dataframe[time_column].iloc[j]) + &#39;00&#39; elif len(str(dataframe[time_column].iloc[j])) == 4: dataframe[time_column].iloc[j] = str(dataframe[time_column].iloc[j]) + &#39;00&#39; # Adding &#39;:&#39; and &#39;/&#39; to match the time format. for k in range(len(dataframe)): dataframe[date_column].iloc[k] = str(dataframe[date_column].iloc[k])[:4] + &#39;/&#39; + str(dataframe[date_column].iloc[k])[4:6] + &#39;/&#39; + str(dataframe[date_column].iloc[k])[6:8] dataframe[time_column].iloc[k] = str(dataframe[time_column].iloc[k])[:2] + &#39;:&#39; + str(dataframe[time_column].iloc[k])[2:4] + &#39;:&#39; + str(dataframe[time_column].iloc[k])[4:6] # Creating new column for the datetime. dataframe[new_column_name] = dataframe[date_column] + &#39; &#39; + dataframe[time_column] # Converting the newly create column to datetime. pd.to_datetime(dataframe[new_column_name]) # We might want to remove the &#39;date_column&#39; and &#39;time_column&#39; we used to create the &#39;datetime column&#39;. # On the other hand if we want to leave them in we can comment out the lines below. dataframe.drop([date_column, time_column], axis = 1, inplace = True) dataframe.to_csv(filtered_file_list[i], encoding=&#39;utf-8&#39;) # return dataframe.head() . columns_to_dateframe_column(pandas_file_dir, &#39;measurement_date&#39;, &#39;measurement_time&#39;, &#39;measurement_datetime&#39;) columns_to_dateframe_column(pandas_file_dir, &#39;file_creation_date&#39;, &#39;file_creation_time&#39;, &#39;file_creation_datetime&#39;) . Let&#39;s see an example of the work we have done so far. . test_2 = pd.read_csv(pandas_file_dir[0], index_col = &#39;Unnamed: 0&#39;) . test_2.head() . record_identifier meter_number consumption file_type_identifier company_id file_generation_number measurement_datetime file_creation_datetime . 1 CONSU | 2 | 10.28 | SMRT | GAZ | PN000001 | 2019/10/14 11:00:00 | 2019/10/16 10:29:39 | . 2 CONSU | 2 | 2.84 | SMRT | GAZ | PN000001 | 2019/10/14 12:00:00 | 2019/10/16 10:29:39 | . 3 CONSU | 2 | 14.65 | SMRT | GAZ | PN000001 | 2019/10/14 13:00:00 | 2019/10/16 10:29:39 | . 4 CONSU | 2 | 11.69 | SMRT | GAZ | PN000001 | 2019/10/14 14:00:00 | 2019/10/16 10:29:39 | . 5 CONSU | 2 | 14.02 | SMRT | GAZ | PN000001 | 2019/10/14 15:00:00 | 2019/10/16 10:29:39 | . We can see that some of the information in the columns remains the same. But I prefer to leave it like that. . Next we can combine all the files from the &#39;pandas_data&#39; folder. To make that file unique to the we can see that the file name has appended the file creation time. . # Empty list. df_list = [] for i in range(len(pandas_file_dir)): dataframe = pd.read_csv(pandas_file_dir[i], index_col = &#39;Unnamed: 0&#39;) df_list.append(dataframe) combined_dataframe = pd.concat(df_list, axis = 0) combined_dataframe.to_csv(&#39;combined_dataframe_&#39; + str(strftime(&quot;%Y-%m-%d_%H:%M:%S&quot;, gmtime())).replace(&#39;:&#39;,&#39;.&#39;) + &#39;.csv&#39;) . We can check in the main folder to see the name of the combined dataframe. . Now there are columns with data that is constant, but it might be useful to let it stay. After all it is not hard to delete columns or to combine the content of the all of the constant columns and combine it into one. For now I am happy with the result. . . SQLite3 . # Instantiate new table con = sql.connect(&#39;./gas_metering_data.db&#39;) cur = con.cursor() cur.execute(&quot;CREATE TABLE IF NOT EXISTS gas_table (record_identifier, meter_number, consumption, file_type_identifier, company_id, file_generation_number, measurement_datetime, file_creation_datetime);&quot;) # use your column names here with open(&#39;combined_dataframe_2021-09-12_07.07.13.csv&#39;, &#39;r&#39;) as fin: dr = csv.DictReader(fin) # comma is default delimiter to_db = [(i[&#39;record_identifier&#39;], i[&#39;meter_number&#39;], i[&#39;consumption&#39;], i[&#39;file_type_identifier&#39;], i[&#39;company_id&#39;], i[&#39;file_generation_number&#39;], i[&#39;measurement_datetime&#39;], i[&#39;file_creation_datetime&#39;]) for i in dr] cur.executemany(&quot;INSERT INTO gas_table (record_identifier, meter_number, consumption, file_type_identifier, company_id, file_generation_number, measurement_datetime, file_creation_datetime) VALUES (?, ?, ?, ?, ?, ?, ?, ?);&quot;, to_db) con.commit() con.close() . The above cell creates SQLite3 table. It works and can be viewed online. . Below you can see how I tried to amend the write/read options of the file/folder. I used to get: . OperationalError: unable to open database file. . os.chmod(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, 0o664) . os.chmod( &#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IWOTH | stat.S_IXOTH | stat.S_IEXEC | stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO | stat.S_IREAD | stat.S_IWRITE) # S_IRUSR (00400) read by owner # S_IWUSR (00200) write by owner # S_IXUSR (00100) execute/search by owner # S_IRGRP (00040) read by group # S_IWGRP (00020) write by group # S_IXGRP (00010) execute/search by group # S_IROTH (00004) read by others # S_IWOTH (00002) write by others # S_IXOTH (000 # stat.S_ISUID : Set user ID on execution # stat.S_ISGID : Set group ID on execution # stat.S_ENFMT : Record locking enforced # stat.S_ISVTX : Save text image after execution # stat.S_IREAD : Read by owner. # stat.S_IWRITE : Write by owner. # stat.S_IEXEC : Execute by owner. # stat.S_IRWXU : Read, write, and execute by owner # stat.S_IRUSR : Read by owner # stat.S_IWUSR : Write by owner. # stat.S_IXUSR : Execute by owner. # stat.S_IRWXG : Read, write, and execute by group # stat.S_IRGRP : Read by group # stat.S_IWGRP : Write by group # stat.S_IXGRP : Execute by group # stat.S_IRWXO : Read, write, and execute by others. # stat.S_IROTH : Read by others # stat.S_IWOTH : Write by others # stat.S_IXOTH : Execute by others . This is the actual SQL query. . conn = sql.connect(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;) gas_metering_data = pd.read_sql(&#39;SELECT * FROM gas_table&#39;, conn) gas_metering_data.head() . record_identifier meter_number consumption file_type_identifier company_id file_generation_number measurement_datetime file_creation_datetime . 0 CONSU | 2 | 10.28 | SMRT | GAZ | PN000001 | 2019/10/14 11:00:00 | 2019/10/16 10:29:39 | . 1 CONSU | 2 | 2.84 | SMRT | GAZ | PN000001 | 2019/10/14 12:00:00 | 2019/10/16 10:29:39 | . 2 CONSU | 2 | 14.65 | SMRT | GAZ | PN000001 | 2019/10/14 13:00:00 | 2019/10/16 10:29:39 | . 3 CONSU | 2 | 11.69 | SMRT | GAZ | PN000001 | 2019/10/14 14:00:00 | 2019/10/16 10:29:39 | . 4 CONSU | 2 | 14.02 | SMRT | GAZ | PN000001 | 2019/10/14 15:00:00 | 2019/10/16 10:29:39 | . def sql_query(database_path, query): &#39;&#39;&#39; This function does SQL queries. &#39;&#39;&#39; conn = sql.connect(database_path) gas_metering_data = pd.read_sql(query, conn) return gas_metering_data . . Below you can see example queries. . # -- SELECT COUNT ( DISTINCT meter_number ) FROM gas_table; sql_query(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, &#39;SELECT COUNT ( DISTINCT meter_number ) FROM gas_table&#39;) . COUNT ( DISTINCT meter_number ) . 0 10 | . # -- SELECT * FROM gas_table WHERE meter_number = &#39;9&#39;; meter_9_data = sql_query(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, &#39;SELECT * FROM gas_table WHERE meter_number = &quot;9&quot;&#39;) meter_9_data.head() . record_identifier meter_number consumption file_type_identifier company_id file_generation_number measurement_datetime file_creation_datetime . 0 CONSU | 9 | 15.43 | SMRT | GAZ | PN000005 | 2019/10/15 13:00:00 | 2019/10/16 10:29:44 | . 1 CONSU | 9 | 9.08 | SMRT | GAZ | PN000005 | 2019/10/15 14:00:00 | 2019/10/16 10:29:44 | . 2 CONSU | 9 | 4.69 | SMRT | GAZ | PN000005 | 2019/10/15 15:00:00 | 2019/10/16 10:29:44 | . 3 CONSU | 9 | 6.24 | SMRT | GAZ | PN000005 | 2019/10/15 16:00:00 | 2019/10/16 10:29:44 | . 4 CONSU | 9 | 11.89 | SMRT | GAZ | PN000005 | 2019/10/15 17:00:00 | 2019/10/16 10:29:44 | . # -- SELECT COUNT ( DISTINCT file_generation_number ) FROM gas_table; sql_query(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, &#39;SELECT COUNT ( DISTINCT file_generation_number ) FROM gas_table&#39;) . COUNT ( DISTINCT file_generation_number ) . 0 10 | . # -- SELECT file_generation_number FROM gas_table ORDER BY file_generation_number DESC LIMIT 1; sql_query(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, &#39;SELECT file_generation_number FROM gas_table ORDER BY file_generation_number DESC LIMIT 1&#39;) . file_generation_number . 0 PN000010 | . # -- SELECT measurement_datetime, consumption # -- FROM gas_table # -- WHERE measurement_datetime BETWEEN &quot;2019/10/14 11:00:00&quot; # -- AND &quot;2019/10/14 23:00:00&quot; AND meter_number = &quot;7&quot;; meter_7_consumption = sql_query(&#39;C:/Users/Jessica/Desktop/- Mladen Tsolov - GazpromEnergyDataEngineerCodeTest/gas_metering_data.db&#39;, &#39;SELECT measurement_datetime, consumption FROM gas_table WHERE measurement_datetime BETWEEN &quot;2019/10/14 11:00:00&quot; AND &quot;2019/10/14 23:00:00&quot; AND meter_number = &quot;7&quot;&#39;) meter_7_consumption.head() . measurement_datetime consumption . 0 2019/10/14 11:00:00 | 12.01 | . 1 2019/10/14 12:00:00 | 5.74 | . 2 2019/10/14 13:00:00 | 19.36 | . 3 2019/10/14 14:00:00 | 6.59 | . 4 2019/10/14 15:00:00 | 3.86 | . meter_7_consumption.index = meter_7_consumption.index.astype(np.int64) meter_7_consumption.consumption = meter_7_consumption.consumption.astype(np.float64) meter_7_consumption.dtypes . measurement_datetime object consumption float64 dtype: object . plt.plot(meter_7_consumption.index, meter_7_consumption.consumption) plt.title(&#39;Gas consumption measured by meter 7&#39;) plt.xlabel(&#39;Meter readings&#39;) plt.ylabel(&#39;Gas consumption&#39;) plt.show() . Below you can see a sample function that creates a table. . def create_new_sql_table(csv_file_name, database_file_name): try: sql_query_dataframe = pd.read_csv(csv_file_name, index_col = &#39;Unnamed: 0&#39;) conn = sql.connect(database_file_name + &#39;.db&#39;) sql_query_dataframe.to_sql(csv_file_name, conn) return (f&#39;{database_file_name}.db created successfully.&#39;) except FileNotFoundError: return (&#39;FileNotFoundError: [WinError 3] The system cannot find the specified path. Please try again.&#39;) except ValueError: return (f&#39;ValueError: Table {database_file_name}.db already exists.&#39;) . . The SQL queries can be done online as well. We can upload the database file to the URL and we can run the queries. . # -- Shows the complete table # -- SELECT * FROM gas_table; # -- 1. How many meters are in the dataset? # -- SELECT COUNT ( DISTINCT meter_number ) FROM gas_table; # -- 2. What is all the data for a given meter? # -- SELECT * FROM gas_table WHERE meter_number = &#39;9&#39;; # -- 3. How many files have we recieved? # -- SELECT COUNT ( DISTINCT file_generation_number ) FROM gas_table; # -- 4. What was the last file to be recieved? # -- SELECT file_generation_number FROM gas_table ORDER BY file_generation_number DESC LIMIT 1; # -- 5. Gas consumption for one meter for a day? # -- SELECT measurement_datetime, consumption # -- FROM gas_table # -- WHERE measurement_datetime BETWEEN &quot;2019/10/14 11:00:00&quot; # -- AND &quot;2019/10/14 23:00:00&quot; AND meter_number = &quot;7&quot;; . References: . https://docs.python.org/3/library/shutil.html . https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-inpython . https://stackoverflow.com/questions/7356043/how-to-delete-specificstrings-from-a-file .",
            "url": "https://mrt5010v.github.io/Fastpages-Portfolio/data%20science/data%20visualization/sqlite3/pandas/working%20with%20files%20using%20python/sql%20queries/2022/03/18/Gazprom-project-FINAL.html",
            "relUrl": "/data%20science/data%20visualization/sqlite3/pandas/working%20with%20files%20using%20python/sql%20queries/2022/03/18/Gazprom-project-FINAL.html",
            "date": " • Mar 18, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Mladen Tsolov and I am Data Science and Machine Learning Enthusiast. Mladen Tsolov Portfolio Main Page: &lt;— Click here to see my projects. .",
          "url": "https://mrt5010v.github.io/Fastpages-Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mrt5010v.github.io/Fastpages-Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}